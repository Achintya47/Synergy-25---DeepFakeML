{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8f54c7d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-03T11:35:30.015647Z",
     "iopub.status.busy": "2025-11-03T11:35:30.015239Z",
     "iopub.status.idle": "2025-11-03T11:35:30.020692Z",
     "shell.execute_reply": "2025-11-03T11:35:30.019856Z"
    },
    "papermill": {
     "duration": 0.012955,
     "end_time": "2025-11-03T11:35:30.021815",
     "exception": false,
     "start_time": "2025-11-03T11:35:30.008860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "478f671f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T11:35:30.027974Z",
     "iopub.status.busy": "2025-11-03T11:35:30.027698Z",
     "iopub.status.idle": "2025-11-03T11:37:02.626858Z",
     "shell.execute_reply": "2025-11-03T11:37:02.626171Z"
    },
    "papermill": {
     "duration": 92.603783,
     "end_time": "2025-11-03T11:37:02.628246",
     "exception": false,
     "start_time": "2025-11-03T11:35:30.024463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting thop\r\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from thop) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.19.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (4.15.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2025.9.0)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->thop)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->thop)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->thop)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->thop)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->thop)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->thop)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->thop)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->thop)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->thop)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->thop)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->thop) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->thop) (3.0.2)\r\n",
      "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\r\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 thop-0.1.1.post2209072238\r\n"
     ]
    }
   ],
   "source": [
    "!pip install thop\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import DenseNet121_Weights, EfficientNet_B2_Weights\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "import glob\n",
    "import copy\n",
    "from PIL import Image\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "from thop import profile # For FLOPs calculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74bbfa48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T11:37:02.682100Z",
     "iopub.status.busy": "2025-11-03T11:37:02.681732Z",
     "iopub.status.idle": "2025-11-03T11:37:02.791227Z",
     "shell.execute_reply": "2025-11-03T11:37:02.790247Z"
    },
    "papermill": {
     "duration": 0.137278,
     "end_time": "2025-11-03T11:37:02.792252",
     "exception": true,
     "start_time": "2025-11-03T11:37:02.654974",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_real_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19/3464060965.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Data paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mTRAIN_REAL_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_real_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mTRAIN_FAKE_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fake_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mTEST_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_real_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Hyperparameters and Configuration ---\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 40 # Increased epochs for better tuning\n",
    "IMG_SIZE = 224 \n",
    "PATIENCE = 7 # Increased patience\n",
    "\n",
    "# Data paths\n",
    "TRAIN_REAL_DIR = train_real_dir\n",
    "TRAIN_FAKE_DIR = train_fake_dir\n",
    "TEST_DIR = test_dir\n",
    "\n",
    "# Model save paths\n",
    "DENSENET_PATH = \"best_densenet.pth\"\n",
    "EFFICIENTNET_B2_PATH = \"best_efficientnet_b2.pth\"\n",
    "COMPLEX_CNN_V2_PATH = \"best_complex_cnn_v2.pth\"\n",
    "MODERN_CNN_PATH = \"best_modern_cnn.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5d82ab",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DeepfakeTrainDataset(Dataset):\n",
    "    def __init__(self, real_dir, fake_dir, transform=None):\n",
    "        self.transform = transform\n",
    "        self.image_files = []\n",
    "        for filename in glob.glob(os.path.join(real_dir, \"*.png\")):\n",
    "            self.image_files.append((filename, 0.0))\n",
    "        for filename in glob.glob(os.path.join(fake_dir, \"*.png\")):\n",
    "            self.image_files.append((filename, 1.0))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.image_files[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            image = Image.new(\"RGB\", (IMG_SIZE, IMG_SIZE), color=\"black\")\n",
    "            label = 0.0\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "class DeepfakeTestDataset(Dataset):\n",
    "    def __init__(self, test_dir, transform=None):\n",
    "        self.transform = transform\n",
    "        self.image_files = glob.glob(os.path.join(test_dir, \"*.png\"))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        filename = os.path.basename(img_path)\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading test image {img_path}: {e}\")\n",
    "            image = Image.new(\"RGB\", (IMG_SIZE, IMG_SIZE), color=\"black\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, filename\n",
    "\n",
    "# --- Data Transforms (Copied from V1) ---\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=20),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "# --- Create DataLoaders (Copied from V1) ---\n",
    "full_dataset = DeepfakeTrainDataset(TRAIN_REAL_DIR, TRAIN_FAKE_DIR, transform=train_transforms)\n",
    "total_size = len(full_dataset)\n",
    "val_size = int(total_size * 0.2)\n",
    "train_size = total_size - val_size\n",
    "\n",
    "if train_size > 0 and val_size > 0:\n",
    "    train_dataset, val_dataset_with_aug = random_split(full_dataset, [train_size, val_size])\n",
    "    val_dataset = DeepfakeTrainDataset(TRAIN_REAL_DIR, TRAIN_FAKE_DIR, transform=val_test_transforms)\n",
    "    val_dataset.image_files = [full_dataset.image_files[i] for i in val_dataset_with_aug.indices]\n",
    "else:\n",
    "    print(\"Dataset too small to split. Using full dataset for both training and validation.\")\n",
    "    train_dataset = full_dataset\n",
    "    val_dataset = DeepfakeTrainDataset(TRAIN_REAL_DIR, TRAIN_FAKE_DIR, transform=val_test_transforms)\n",
    "\n",
    "print(f\"Total training images: {len(train_dataset)}\")\n",
    "print(f\"Total validation images: {len(val_dataset)}\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_dataset = DeepfakeTestDataset(TEST_DIR, transform=val_test_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "print(f\"Test images: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70862019",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs, patience, model_save_path):\n",
    "    \"\"\"\n",
    "    Main training and validation loop with early stopping.\n",
    "    \"\"\"\n",
    "    \n",
    "    if DEVICE == \"cuda\":\n",
    "        torch.cuda.reset_peak_memory_stats(DEVICE)\n",
    "        \n",
    "    start_time = time.time()\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'val_precision': [], 'val_recall': [], 'val_f1': []}\n",
    "    \n",
    "    best_model_state = copy.deepcopy(model.state_dict())\n",
    "    best_val_loss = float('inf')\n",
    "    early_stopping_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # --- Training Phase ---\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE).unsqueeze(1) # Match shape for BCEWithLogitsLoss [batch_size, 1]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            preds = torch.sigmoid(outputs) > 0.5\n",
    "            running_corrects += torch.sum(preds == (labels > 0.5))\n",
    "            train_total += labels.size(0)\n",
    "\n",
    "        epoch_train_loss = running_loss / train_total\n",
    "        epoch_train_acc = running_corrects.double() / train_total\n",
    "        history['train_loss'].append(epoch_train_loss)\n",
    "        history['train_acc'].append(epoch_train_acc.item())\n",
    "        print(f'Train Loss: {epoch_train_loss:.4f} Acc: {epoch_train_acc:.4f}')\n",
    "\n",
    "        # --- Validation Phase ---\n",
    "        model.eval()   # Set model to evaluate mode\n",
    "        running_val_loss = 0.0\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                labels = labels.to(DEVICE).unsqueeze(1)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_val_loss += loss.item() * inputs.size(0)\n",
    "                preds = torch.sigmoid(outputs) > 0.5\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "        \n",
    "        if len(all_labels) > 0:\n",
    "            val_total = len(all_labels)\n",
    "            epoch_val_loss = running_val_loss / val_total\n",
    "            all_labels = np.array(all_labels).flatten()\n",
    "            all_preds = np.array(all_preds).flatten()\n",
    "            epoch_val_acc = accuracy_score(all_labels, all_preds)\n",
    "            epoch_val_precision = precision_score(all_labels, all_preds, zero_division=0)\n",
    "            epoch_val_recall = recall_score(all_labels, all_preds, zero_division=0)\n",
    "            epoch_val_f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "        else:\n",
    "            print(\"Validation set is empty. Skipping metrics.\")\n",
    "            epoch_val_loss, epoch_val_acc, epoch_val_precision, epoch_val_recall, epoch_val_f1 = 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "            \n",
    "        history['val_loss'].append(epoch_val_loss)\n",
    "        history['val_acc'].append(epoch_val_acc)\n",
    "        history['val_precision'].append(epoch_val_precision)\n",
    "        history['val_recall'].append(epoch_val_recall)\n",
    "        history['val_f1'].append(epoch_val_f1)\n",
    "\n",
    "        print(f'Val Loss: {epoch_val_loss:.4f} Acc: {epoch_val_acc:.4f}')\n",
    "        print(f'Val Precision: {epoch_val_precision:.4f} Recall: {epoch_val_recall:.4f} F1: {epoch_val_f1:.4f}')\n",
    "\n",
    "        # --- Early Stopping Check ---\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            torch.save(best_model_state, model_save_path)\n",
    "            model_size_mb = os.path.getsize(model_save_path) / (1024 * 1024)\n",
    "            print(f\"New best model saved to {model_save_path} (Size: {model_size_mb:.2f} MB)\")\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            print(f\"Early stopping counter: {early_stopping_counter}/{patience}\")\n",
    "        \n",
    "        if early_stopping_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_duration_sec = end_time - start_time\n",
    "    print(f'\\nTraining complete in {total_duration_sec // 60:.0f}m {total_duration_sec % 60:.0f}s')\n",
    "    print(f'Best val Loss: {best_val_loss:4f}')\n",
    "    \n",
    "    if DEVICE == \"cuda\":\n",
    "        peak_mem_mb = torch.cuda.max_memory_allocated(DEVICE) / (1024 * 1024)\n",
    "        print(f'Peak GPU memory allocated during training: {peak_mem_mb:.2f} MB')\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_save_path))\n",
    "    return history, total_duration_sec\n",
    "\n",
    "def plot_history(history, title):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Val Loss')\n",
    "    plt.legend()\n",
    "    plt.title(f'{title} - Loss')\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Train Acc')\n",
    "    plt.plot(history['val_acc'], label='Val Acc')\n",
    "    plt.legend()\n",
    "    plt.title(f'{title} - Accuracy')\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(history['val_precision'], label='Val Precision')\n",
    "    plt.plot(history['val_recall'], label='Val Recall')\n",
    "    plt.legend()\n",
    "    plt.title(f'{title} - Precision & Recall')\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(history['val_f1'], label='Val F1-Score')\n",
    "    plt.legend()\n",
    "    plt.title(f'{title} - F1-Score')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990effa4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"--- Training Model 1: DenseNet-121 ---\")\n",
    "\n",
    "# 1. Load pre-trained model\n",
    "model_densenet = models.densenet121(weights=DenseNet121_Weights.DEFAULT)\n",
    "\n",
    "# 2. Freeze all parameters\n",
    "for param in model_densenet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 3. Replace the final layer\n",
    "in_features = model_densenet.classifier.in_features\n",
    "model_densenet.classifier = nn.Linear(in_features, 1)\n",
    "\n",
    "# 4. Move model to device\n",
    "model_densenet = model_densenet.to(DEVICE)\n",
    "\n",
    "# 5. Calculate FLOPs and Params\n",
    "try:\n",
    "    dummy_input = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(DEVICE)\n",
    "    flops, params = profile(model_densenet, inputs=(dummy_input, ), verbose=False)\n",
    "    print(f\"DenseNet-121: {flops/1e9:.2f} GFLOPs, {params/1e6:.2f} MParams\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not calculate FLOPs for DenseNet-121: {e}\")\n",
    "    \n",
    "# 6. Define Loss and Optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer_densenet = optim.Adam(model_densenet.classifier.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# 7. Train the model\n",
    "densenet_history, densenet_time = train_model(model_densenet, criterion, optimizer_densenet, train_loader, val_loader, \n",
    "                                            num_epochs=NUM_EPOCHS, patience=PATIENCE, model_save_path=DENSENET_PATH)\n",
    "\n",
    "# 8. Plot history\n",
    "plot_history(densenet_history, \"DenseNet-121 Fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fe6935",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"--- Training Model 2: EfficientNet-B2 (Unfrozen) ---\")\n",
    "\n",
    "# 1. Load pre-trained model\n",
    "model_efficientnet_b2 = models.efficientnet_b2(weights=EfficientNet_B2_Weights.DEFAULT)\n",
    "\n",
    "# 2. Freeze all parameters INITIALLY\n",
    "for param in model_efficientnet_b2.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 3. Replace the final layer (which will be trainable by default)\n",
    "in_features = model_efficientnet_b2.classifier[1].in_features\n",
    "model_efficientnet_b2.classifier[1] = nn.Linear(in_features, 1)\n",
    "\n",
    "# 4. Unfreeze the last two feature blocks\n",
    "print(\"Unfreezing last two blocks of EfficientNet-B2...\")\n",
    "for param in model_efficientnet_b2.features[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model_efficientnet_b2.features[-2].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 5. Collect parameters that need gradients\n",
    "params_to_update = []\n",
    "print(\"Parameters to be trained:\")\n",
    "for name, param in model_efficientnet_b2.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        params_to_update.append(param)\n",
    "        print(f\"\\t{name}\")\n",
    "\n",
    "# 6. Move model to device\n",
    "model_efficientnet_b2 = model_efficientnet_b2.to(DEVICE)\n",
    "\n",
    "# 7. Calculate FLOPs and Params\n",
    "try:\n",
    "    dummy_input = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(DEVICE)\n",
    "    flops, params = profile(model_efficientnet_b2, inputs=(dummy_input, ), verbose=False)\n",
    "    print(f\"EfficientNet-B2: {flops/1e9:.2f} GFLOPs, {params/1e6:.2f} MParams\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not calculate FLOPs for EfficientNet-B2: {e}\")\n",
    "\n",
    "# 8. Define Loss and Optimizer\n",
    "# We only optimize the parameters we explicitly unfroze\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer_efficientnet_b2 = optim.Adam(params_to_update, lr=LEARNING_RATE)\n",
    "\n",
    "# 9. Train the model\n",
    "efficientnet_b2_history, efficientnet_b2_time = train_model(model_efficientnet_b2, criterion, optimizer_efficientnet_b2, train_loader, val_loader, \n",
    "                                                         num_epochs=NUM_EPOCHS, patience=PATIENCE, model_save_path=EFFICIENTNET_B2_PATH)\n",
    "\n",
    "# 10. Plot history\n",
    "plot_history(efficientnet_b2_history, \"EfficientNet-B2 (Unfrozen) Tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7ddc95",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ComplexCNN_v2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComplexCNN_v2, self).__init__()\n",
    "        \n",
    "        # Input: [B, 3, 224, 224]\n",
    "        self.conv1 = self._conv_block(3, 16, 3, 1, 1) # -> [B, 16, 112, 112]\n",
    "        self.conv2 = self._conv_block(16, 32, 3, 1, 1) # -> [B, 32, 56, 56]\n",
    "        self.conv3 = self._conv_block(32, 64, 3, 1, 1) # -> [B, 64, 28, 28]\n",
    "        self.conv4 = self._conv_block(64, 128, 3, 1, 1) # -> [B, 128, 14, 14]\n",
    "        \n",
    "        # --- THIS IS THE FIX ---\n",
    "        # Global Average Pooling: Takes [B, 128, 14, 14] -> [B, 128, 1, 1]\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # New FC stack with far fewer parameters\n",
    "        self.fc_stack = nn.Sequential(\n",
    "            nn.Flatten(), # -> [B, 128]\n",
    "            nn.Linear(128, 512), # 128 * 512 = ~65k params (vs 12.9M!)\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 1) # 512 * 1 = ~512 params\n",
    "        )\n",
    "        # --- END FIX ---\n",
    "\n",
    "    def _conv_block(self, in_channels, out_channels, kernel, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel, stride=stride, padding=padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.pool(x) # Apply GAP\n",
    "        x = self.fc_stack(x) # Apply new FC stack\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09c2513",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"--- Training Model 3: ComplexCNN_v2 ---\")\n",
    "\n",
    "# 1. Instantiate model\n",
    "model_complex_cnn_v2 = ComplexCNN_v2().to(DEVICE)\n",
    "\n",
    "# 2. Calculate FLOPs and Params\n",
    "try:\n",
    "    dummy_input = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(DEVICE)\n",
    "    flops, params = profile(model_complex_cnn_v2, inputs=(dummy_input, ), verbose=False)\n",
    "    print(f\"ComplexCNN_v2: {flops/1e9:.2f} GFLOPs, {params/1e6:.2f} MParams\")\n",
    "    print(\"Note: Params should be dramatically lower than V1's 12.94M\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not calculate FLOPs for ComplexCNN_v2: {e}\")\n",
    "\n",
    "# 3. Define Loss and Optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer_complex_cnn_v2 = optim.Adam(model_complex_cnn_v2.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# 4. Train the model\n",
    "complex_cnn_v2_history, complex_cnn_v2_time = train_model(model_complex_cnn_v2, criterion, optimizer_complex_cnn_v2, train_loader, val_loader, \n",
    "                                                         num_epochs=NUM_EPOCHS, patience=PATIENCE, model_save_path=COMPLEX_CNN_V2_PATH)\n",
    "\n",
    "# 5. Plot history\n",
    "plot_history(complex_cnn_v2_history, \"ComplexCNN_v2 Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aa2529",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModernCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModernCNN, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1: [B, 3, 224, 224] -> [B, 32, 112, 112]\n",
    "            self._vgg_block(3, 32, 2),\n",
    "            # Block 2: -> [B, 64, 56, 56]\n",
    "            self._vgg_block(32, 64, 2),\n",
    "            # Block 3: -> [B, 128, 28, 28]\n",
    "            self._vgg_block(64, 128, 2),\n",
    "            # Block 4: -> [B, 256, 14, 14]\n",
    "            self._vgg_block(128, 256, 2),\n",
    "            # Block 5: -> [B, 512, 7, 7]\n",
    "            self._vgg_block(256, 512, 2)\n",
    "        )\n",
    "        \n",
    "        # Global Average Pooling: [B, 512, 7, 7] -> [B, 512, 1, 1]\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(), # -> [B, 512]\n",
    "            nn.Linear(512, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def _vgg_block(self, in_channels, out_channels, num_convs):\n",
    "        layers = []\n",
    "        for _ in range(num_convs):\n",
    "            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False))\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "            layers.append(nn.GELU())\n",
    "            in_channels = out_channels\n",
    "        layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b8981c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"--- Training Model 4: ModernCNN ---\")\n",
    "\n",
    "# 1. Instantiate model\n",
    "model_modern_cnn = ModernCNN().to(DEVICE)\n",
    "\n",
    "# 2. Calculate FLOPs and Params\n",
    "try:\n",
    "    dummy_input = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(DEVICE)\n",
    "    flops, params = profile(model_modern_cnn, inputs=(dummy_input, ), verbose=False)\n",
    "    print(f\"ModernCNN: {flops/1e9:.2f} GFLOPs, {params/1e6:.2f} MParams\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not calculate FLOPs for ModernCNN: {e}\")\n",
    "\n",
    "# 3. Define Loss and Optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer_modern_cnn = optim.Adam(model_modern_cnn.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# 4. Train the model\n",
    "modern_cnn_history, modern_cnn_time = train_model(model_modern_cnn, criterion, optimizer_modern_cnn, train_loader, val_loader, \n",
    "                                                  num_epochs=NUM_EPOCHS, patience=PATIENCE, model_save_path=MODERN_CNN_PATH)\n",
    "\n",
    "# 5. Plot history\n",
    "plot_history(modern_cnn_history, \"ModernCNN Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5e0509",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_predictions(model, loader, device):\n",
    "    \"\"\"Runs inference on the test set and returns a prediction dictionary.\"\"\"\n",
    "    model.eval() \n",
    "    predictions = {}\n",
    "    with torch.no_grad():\n",
    "        for inputs, filenames in tqdm(loader, desc=\"Generating Predictions\"):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy().flatten()\n",
    "            for filename, prob in zip(filenames, probs):\n",
    "                predictions[filename] = float(prob)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ca7c9f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"--- Generating Final Predictions (V2 Models) ---\")\n",
    "\n",
    "# --- DenseNet-121 Predictions ---\n",
    "try:\n",
    "    print(\"Loading best DenseNet-121 model...\")\n",
    "    model_densenet.load_state_dict(torch.load(DENSENET_PATH))\n",
    "    preds = generate_predictions(model_densenet, test_loader, DEVICE)\n",
    "    with open(\"densenet_predictions.json\", \"w\") as f:\n",
    "        json.dump(preds, f, indent=4)\n",
    "    print(\"DenseNet-121 predictions saved.\")\n",
    "except (FileNotFoundError, NameError):\n",
    "    print(\"DenseNet model file not found. Skipping.\")\n",
    "\n",
    "# --- EfficientNet-B2 Predictions ---\n",
    "try:\n",
    "    print(\"Loading best EfficientNet-B2 model...\")\n",
    "    model_efficientnet_b2.load_state_dict(torch.load(EFFICIENTNET_B2_PATH))\n",
    "    preds = generate_predictions(model_efficientnet_b2, test_loader, DEVICE)\n",
    "    with open(\"efficientnet_b2_predictions.json\", \"w\") as f:\n",
    "        json.dump(preds, f, indent=4)\n",
    "    print(\"EfficientNet-B2 predictions saved.\")\n",
    "except (FileNotFoundError, NameError):\n",
    "    print(\"EfficientNet-B2 model file not found. Skipping.\")\n",
    "\n",
    "# --- ComplexCNN_v2 Predictions ---\n",
    "try:\n",
    "    print(\"Loading best ComplexCNN_v2 model...\")\n",
    "    model_complex_cnn_v2.load_state_dict(torch.load(COMPLEX_CNN_V2_PATH))\n",
    "    preds = generate_predictions(model_complex_cnn_v2, test_loader, DEVICE)\n",
    "    with open(\"complex_cnn_v2_predictions.json\", \"w\") as f:\n",
    "        json.dump(preds, f, indent=4)\n",
    "    print(\"ComplexCNN_v2 predictions saved.\")\n",
    "except (FileNotFoundError, NameError):\n",
    "    print(\"ComplexCNN_v2 model file not found. Skipping.\")\n",
    "\n",
    "# --- ModernCNN Predictions ---\n",
    "try:\n",
    "    print(\"Loading best ModernCNN model...\")\n",
    "    model_modern_cnn.load_state_dict(torch.load(MODERN_CNN_PATH))\n",
    "    preds = generate_predictions(model_modern_cnn, test_loader, DEVICE)\n",
    "    with open(\"modern_cnn_predictions.json\", \"w\") as f:\n",
    "        json.dump(preds, f, indent=4)\n",
    "    print(\"ModernCNN predictions saved.\")\n",
    "except (FileNotFoundError, NameError):\n",
    "    print(\"ModernCNN model file not found. Skipping.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867b9dbb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clean up GPU memory\n",
    "if DEVICE == \"cuda\":\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 99.115029,
   "end_time": "2025-11-03T11:37:05.112864",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-03T11:35:25.997835",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
